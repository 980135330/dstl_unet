{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import simplejson\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import threading\n",
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arg_scope(H, phase):\n",
    "    '''\n",
    "    This returns the arg_scope for slim.arg_scope(), which defines the options for slim.functions\n",
    "    '''\n",
    "    padding = H['padding']\n",
    "    is_training = {'train': True, 'validate': False}[phase]\n",
    "    pool_kernel = [2, 2]\n",
    "    pool_stride = 2\n",
    "\n",
    "    \n",
    "    params = {\n",
    "        \"decay\": 0.997,\n",
    "        \"epsilon\": 0.001,\n",
    "    }\n",
    "\n",
    "    with slim.arg_scope(\n",
    "            func=slim.conv2d, \n",
    "            activation_fn=slim.relu, \n",
    "            padding=padding, \n",
    "            normalizer_fn=slim.batch_norm, \n",
    "            weights_initializer=tf.contrib.layers.variance_scaling_initializer()):\n",
    "        with slim.arg_scope(func=[slim.batch_norm, slim.dropout], is_training=is_training):\n",
    "            with slim.arg_scope(func=slim.max_pool2d, stride=pool_stride, kernel_size=pool_kernel) as sc:\n",
    "                with slim.arg_scope(\n",
    "                    func=slim.conv2d_transpose, \n",
    "                    stride=pool_stride, \n",
    "                    kernel_size=pool_kernel, \n",
    "                    padding=padding):\n",
    "                    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_pred(x_in, H, phase):\n",
    "    '''\n",
    "    This function builds the prediction model\n",
    "    '''\n",
    "    conv_kernel_1 = [1, 1]\n",
    "    conv_kernel_3 = [3, 3]\n",
    "    \n",
    "    early_feature = {}\n",
    "    \n",
    "    with slim.arg_scope(arg_scope(H, phase)):\n",
    "        \n",
    "        scope_name = 'block_1'\n",
    "        x_input = x_in\n",
    "        num_outputs = 64\n",
    "        with tf.variable_scope(values=scope_name):\n",
    "            lay_1 = slim.conv2d(inputs=x_input, kernel_size=conv_kernel_3, num_outputs=num_outputs)\n",
    "            lay_2 = slim.conv2d(inputs=layer_1, kernel_size=conv_kernel_3, num_outputs=num_outputs)\n",
    "            early_feature[scope_name] = layer_2\n",
    "        \n",
    "        scope_name = 'block_2'\n",
    "        x_input = slim.max_pool2d(inputs=layer_2)\n",
    "        num_outputs = 128\n",
    "        with tf.variable_scope(values=scope_name):\n",
    "            lay_1 = slim.conv2d(inputs=x_input, kernel_size=conv_kernel_3, num_outputs=num_outputs)\n",
    "            lay_2 = slim.conv2d(inputs=layer_1, kernel_size=conv_kernel_3, num_outputs=num_outputs)\n",
    "            early_feature[scope_name] = layer_2\n",
    "\n",
    "        scope_name = 'block_3'\n",
    "        x_input = slim.max_pool2d(inputs=layer_2)\n",
    "        num_outputs = 256\n",
    "        with tf.variable_scope(values=scope_name):\n",
    "            lay_1 = slim.conv2d(inputs=x_input, kernel_size=conv_kernel_3, num_outputs=num_outputs)\n",
    "            lay_2 = slim.conv2d(inputs=layer_1, kernel_size=conv_kernel_3, num_outputs=num_outputs)\n",
    "            early_feature[scope_name] = layer_2\n",
    "            \n",
    "        scope_name = 'block_4'\n",
    "        x_input = slim.max_pool2d(inputs=layer_2)\n",
    "        num_outputs = 512\n",
    "        with tf.variable_scope(values=scope_name):\n",
    "            lay_1 = slim.conv2d(inputs=x_input, kernel_size=conv_kernel_3, num_outputs=num_outputs)\n",
    "            lay_2 = slim.conv2d(inputs=layer_1, kernel_size=conv_kernel_3, num_outputs=num_outputs)\n",
    "            early_feature[scope_name] = layer_2\n",
    "\n",
    "        scope_name = 'block_5'\n",
    "        x_input = slim.max_pool2d(inputs=layer_2)\n",
    "        num_outputs = 1024\n",
    "        with tf.variable_scope(values=scope_name):\n",
    "            lay_1 = slim.conv2d(inputs=x_input, kernel_size=conv_kernel_3, num_outputs=num_outputs)\n",
    "            lay_2 = slim.conv2d(inputs=layer_1, kernel_size=conv_kernel_3, num_outputs=num_outputs)\n",
    "            early_feature[scope_name] = layer_2\n",
    "            \n",
    "        scope_name = 'block_6'\n",
    "        num_outputs = 512\n",
    "        trans_layer_2 = slim.conv2d_transpose(inputs=slim.max_pool2d(layer_2), num_outputs=num_outputs)\n",
    "        x_input = slim.max_pool2d(inputs=tf.concat([early_features['block_5'], trans_layer_2], axis=3))\n",
    "        with tf.variable_scope(values=scope_name):\n",
    "            lay_1 = slim.conv2d(inputs=x_input, kernel_size=conv_kernel_3, num_outputs=num_outputs)\n",
    "            lay_2 = slim.conv2d(inputs=layer_1, kernel_size=conv_kernel_3, num_outputs=num_outputs)\n",
    "        return layer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_loss(x_in, H, phase, phase):\n",
    "    '''\n",
    "    This function builds the loss and accuracy\n",
    "    '''\n",
    "    reuse = {'train': False, 'validate': True}[phase]\n",
    "    with tf.variable_scope(reuse=reuse=se):\n",
    "        build_pred(x_in, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build(queues, H):\n",
    "    '''\n",
    "    This function returns the train operation, summary, global step\n",
    "    '''\n",
    "    im_width = H['im_width']\n",
    "    im_height = H['im_height']\n",
    "    num_class = H['num_class']\n",
    "    num_channel = H['num_channel']\n",
    "    batch_size = H['batch_size']\n",
    "    loss, accuracy = {}, {}\n",
    "    for phase in ['train', 'validate']:\n",
    "        x_in = queues[phase].dequeue_many(batch_size)\n",
    "        loss[phase], accuracy[phase] = build_loss(x_in, H, phase)\n",
    "    \n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hypes = './hypes/hypes.json'\n",
    "with open(hypes, 'r') as f:\n",
    "    H = simplejson.load(f)\n",
    "    im_width = H['im_width']\n",
    "    im_height = H['im_height']\n",
    "    num_class = H['num_class']\n",
    "    num_channel = H['num_channel']\n",
    "    queue_size = H['queue_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enqueue_thread(sess, data_gen, coord, phase, enqueue_op):\n",
    "    while not coord.should_stop():\n",
    "        sess.run(enqueue_op, feed_dict={x_in[phase]: data_gen.next()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_in, queues, enqueue_op = {}, {}, {}\n",
    "shape = ((im_width, im_height, num_channel), \n",
    "         (im_width, im_height, num_class)\n",
    "    )\n",
    "for phase in ['train', 'validate']:\n",
    "    x_in[phase] = tf.placeholder(dtype=tf.float32)\n",
    "    queues[phase] = tf.FIFOQueue(capacity=queue_size, shapes=shape, dtypes=(tf.float32,tf.float32))\n",
    "    enqueue_op[phase] = queues[phase].enqueue(x_in[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "build(queues, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'valicate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-cd6b0013a18a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valicate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menqueue_thread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'valicate'"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "coord = tf.train.Coordinator()\n",
    "threads = {}\n",
    "with tf.Session(config=config) as sess:\n",
    "    for phase in ['train', 'valicate']:\n",
    "        threads[phase] = threading.Thread(\n",
    "            target=enqueue_thread, \n",
    "            args=(sess, data_gen[phase], coord, phase, enqueue_op[phase]))\n",
    "        threads[phase].start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord.requst_stop()\n",
    "coord.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
