{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import simplejson\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import threading\n",
    "import tensorflow.contrib.slim as slim\n",
    "from utils import data_utils, train_utils\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def argument_scope(H, phase):\n",
    "    '''\n",
    "    This returns the arg_scope for slim.arg_scope(), which defines the options for slim.functions\n",
    "    '''\n",
    "    padding = H['padding']\n",
    "    is_training = {'train': True, 'validate': False, 'test': False}[phase]\n",
    "    pool_kernel = [2, 2]\n",
    "    pool_stride = 2\n",
    "\n",
    "    \n",
    "    params = {\n",
    "        \"decay\": 0.997,\n",
    "        \"epsilon\": 0.001,\n",
    "    }\n",
    "\n",
    "    with slim.arg_scope([slim.conv2d], \n",
    "                        # slim.relu would raise an error here\n",
    "                        activation_fn=tf.nn.relu, \n",
    "                        padding=padding, \n",
    "                        normalizer_fn=slim.batch_norm, \n",
    "                        # normalizer_fn=None,\n",
    "                        weights_initializer=tf.contrib.layers.variance_scaling_initializer()):\n",
    "        with slim.arg_scope([slim.batch_norm, slim.dropout], is_training=is_training):\n",
    "            with slim.arg_scope([slim.max_pool2d], stride=pool_stride, kernel_size=pool_kernel):\n",
    "                with slim.arg_scope([slim.conv2d_transpose], \n",
    "                                    activation_fn=None, \n",
    "                                    normalizer_fn=None,\n",
    "                                    padding=padding, \n",
    "                                    weights_initializer=tf.contrib.layers.variance_scaling_initializer()) as sc:\n",
    "                    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_pred(x_in, H, phase):\n",
    "    '''\n",
    "    This function builds the prediction model\n",
    "    '''\n",
    "    num_class = H['num_class']\n",
    "    \n",
    "    conv_kernel_1 = [1, 1]\n",
    "    conv_kernel_3 = [3, 3]\n",
    "    pool_kernel = [2, 2]\n",
    "    pool_stride = 2\n",
    "\n",
    "    early_feature = {}\n",
    "    reuse = {'train': False, 'validate': True, 'test': False}[phase]\n",
    "    \n",
    "    with slim.arg_scope(argument_scope(H, phase)):\n",
    "        \n",
    "        scope_name = 'block_1'\n",
    "        x_input = x_in\n",
    "        num_outputs = 64\n",
    "        with tf.variable_scope(scope_name, reuse = reuse):\n",
    "            layer_1 = slim.conv2d(x_input, num_outputs, conv_kernel_3, scope='conv1')\n",
    "            layer_2 = slim.conv2d(layer_1, num_outputs, conv_kernel_3, scope='conv2')\n",
    "            early_feature[scope_name] = layer_2\n",
    "        \n",
    "        scope_name = 'block_2'\n",
    "        x_input = slim.max_pool2d(layer_2)\n",
    "        num_outputs = 128\n",
    "        with tf.variable_scope(scope_name, reuse = reuse):\n",
    "            layer_1 = slim.conv2d(x_input, num_outputs, conv_kernel_3, scope='conv1')\n",
    "            layer_2 = slim.conv2d(layer_1, num_outputs, conv_kernel_3, scope='conv2')\n",
    "            early_feature[scope_name] = layer_2\n",
    "\n",
    "        scope_name = 'block_3'\n",
    "        x_input = slim.max_pool2d(layer_2)\n",
    "        num_outputs = 256\n",
    "        with tf.variable_scope(scope_name, reuse = reuse):\n",
    "            layer_1 = slim.conv2d(x_input, num_outputs, conv_kernel_3, scope='conv1')\n",
    "            layer_2 = slim.conv2d(layer_1, num_outputs, conv_kernel_3, scope='conv2')\n",
    "            early_feature[scope_name] = layer_2\n",
    "            \n",
    "        scope_name = 'block_4'\n",
    "        x_input = slim.max_pool2d(layer_2)\n",
    "        num_outputs = 512\n",
    "        with tf.variable_scope(scope_name, reuse = reuse):\n",
    "            layer_1 = slim.conv2d(x_input, num_outputs, conv_kernel_3, scope='conv1')\n",
    "            layer_2 = slim.conv2d(layer_1, num_outputs, conv_kernel_3, scope='conv2')\n",
    "            early_feature[scope_name] = layer_2\n",
    "\n",
    "        scope_name = 'block_5'\n",
    "        x_input = slim.max_pool2d(layer_2)\n",
    "        num_outputs = 1024\n",
    "        with tf.variable_scope(scope_name, reuse = reuse):\n",
    "            layer_1 = slim.conv2d(x_input, num_outputs, conv_kernel_3, scope='conv1')\n",
    "            layer_2 = slim.conv2d(layer_1, num_outputs, conv_kernel_3, scope='conv2')\n",
    "            early_feature[scope_name] = layer_2\n",
    "            \n",
    "        scope_name = 'block_6'\n",
    "        num_outputs = 512\n",
    "        with tf.variable_scope(scope_name, reuse = reuse):\n",
    "            trans_layer = slim.conv2d_transpose(\n",
    "                layer_2, num_outputs, pool_kernel, pool_stride, scope='conv_trans')\n",
    "            x_input = tf.concat([early_feature['block_4'], trans_layer], axis=3)\n",
    "            layer_1 = slim.conv2d(x_input, num_outputs, conv_kernel_3, scope='conv1')\n",
    "            layer_2 = slim.conv2d(layer_1, num_outputs, conv_kernel_3, scope='conv2')\n",
    "            early_feature[scope_name] = layer_2\n",
    "            \n",
    "        scope_name = 'block_7'\n",
    "        num_outputs = 256\n",
    "        with tf.variable_scope(scope_name, reuse = reuse):\n",
    "            trans_layer = slim.conv2d_transpose(\n",
    "                layer_2, num_outputs, pool_kernel, pool_stride, scope='conv_trans')\n",
    "            x_input = tf.concat([early_feature['block_3'], trans_layer], axis=3)\n",
    "            layer_1 = slim.conv2d(x_input, num_outputs, conv_kernel_3, scope='conv1')\n",
    "            layer_2 = slim.conv2d(layer_1, num_outputs, conv_kernel_3, scope='conv2')\n",
    "            early_feature[scope_name] = layer_2\n",
    "            \n",
    "        scope_name = 'block_8'\n",
    "        num_outputs = 128\n",
    "        with tf.variable_scope(scope_name, reuse = reuse):\n",
    "            trans_layer = slim.conv2d_transpose(\n",
    "                layer_2, num_outputs, pool_kernel, pool_stride, scope='conv_trans')\n",
    "            x_input = tf.concat([early_feature['block_2'], trans_layer], axis=3)\n",
    "            layer_1 = slim.conv2d(x_input, num_outputs, conv_kernel_3, scope='conv1')\n",
    "            layer_2 = slim.conv2d(layer_1, num_outputs, conv_kernel_3, scope='conv2')\n",
    "            early_feature[scope_name] = layer_2\n",
    "        \n",
    "        scope_name = 'block_9'\n",
    "        num_outputs = 64\n",
    "        with tf.variable_scope(scope_name, reuse = reuse):\n",
    "            trans_layer = slim.conv2d_transpose(\n",
    "                layer_2, num_outputs, pool_kernel, pool_stride, scope='conv_trans')\n",
    "            x_input = tf.concat([early_feature['block_1'], trans_layer], axis=3)\n",
    "            layer_1 = slim.conv2d(x_input, num_outputs, conv_kernel_3, scope='conv1')\n",
    "            layer_2 = slim.conv2d(layer_1, num_outputs, conv_kernel_3, scope='conv2')\n",
    "            early_feature[scope_name] = layer_2\n",
    "        \n",
    "        scope_name = 'pred'\n",
    "        with tf.variable_scope(scope_name, reuse = reuse):\n",
    "            # layer_1 = slim.conv2d(layer_2, num_class, conv_kernel_1, scope='conv1', activation_fn=None, normalizer_fn=None)\n",
    "            layer_1 = slim.conv2d(layer_2, 1, conv_kernel_1, scope='conv1', activation_fn=None, normalizer_fn=None)\n",
    "\n",
    "            early_feature[scope_name] = layer_1\n",
    "            \n",
    "            # pred = tf.argmax(tf.nn.softmax(logits=layer_1), axis=3)\n",
    "            pred = tf.sigmoid(layer_1)\n",
    "                \n",
    "        return tf.squeeze(layer_1), tf.squeeze(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hypes = './hypes/hypes.json'\n",
    "with open(hypes, 'r') as f:\n",
    "    H = simplejson.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_in = tf.placeholder(dtype=tf.float32, shape=[1, 3200, 3200, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits, pred = build_pred(img_in, H, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 14, 10, 17]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_utils.test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_data = data_utils.ImageData(16)\n",
    "img_data.load_image()\n",
    "img_data.create_label()\n",
    "img_data.create_train_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from log_dir/8-13_17-48_combo-jaccard/ckpt/ckpt-1001\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, save_path='log_dir/8-13_17-48_combo-jaccard/ckpt/ckpt-1001')\n",
    "    predictions, log = sess.run([pred, logits], \n",
    "                                feed_dict = {img_in: np.reshape(img_data.train_feature[:3200, :3200, :], \n",
    "                                                                [1, 3200, 3200, 16])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3348, 3403, 16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data.train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6726c53d90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7gAAAG5CAYAAACk+pjXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQcAFAACgCwIuAAAAXRBwAQAA6MJ/BnaONjQupztuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f66f69686d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize = [16, 8])\n",
    "axs[0].imshow((predictions > 0.5).astype(int)[0: 3000, 0: 3000], cmap = matplotlib.cm.gray)\n",
    "axs[1].imshow(img_data.label[0: 3000, 0: 3000, 0], cmap = matplotlib.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99828476, 0.041321132)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predictions), np.std(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'log_dir/8-12_14-32_combo-jaccard/ckpt/ckpt-16001'\n",
    "20: 0.072345264 very sparse\n",
    "19: 0.072345264 very sparse\n",
    "18: 0.02 super sparse\n",
    "17: 0.48 a bit full\n",
    "16: 0.1 too sparse\n",
    "15: 0.14 too sparse\n",
    "14: 0.36 OK kinda too full\n",
    "13: 0.2 better than 12\n",
    "12: 0.18 best, still some parts missing\n",
    "11: 0.03 flat\n",
    "10: 0.03 flat\n",
    "9: 0.97 flat\n",
    "8: 1.0 flat \n",
    "7: ~0.5 best\n",
    "6: ~1.0 flat\n",
    "5: ~0.98 flat\n",
    "4: 0.23 best OK rough image with strips\n",
    "3: 1.0 flat\n",
    "\n",
    "model 14 misclassifies road as buildings, model 13 doesn't\n",
    "model 13 can also make good predictions on images with no buildings (true labels). Model trained with images not including the no true label ones, would totally misclassfy these images\n",
    "\n",
    "The result is oscillating!!\n",
    "\n",
    "If the class is highly imblanced, you have to use really large batch size and large momentum, to make sure that the statistics of each effective (taking into account of the momentum) agrees with the statistics of whole training data set. Otherwise, the loss and accuracy will be oscillating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(log), np.std(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize = [16, 8])\n",
    "axs[0].imshow((predictions > 0.8).astype(int)[0: 3000, 0: 3000], cmap = matplotlib.cm.gray)\n",
    "axs[1].imshow(img_data.label[0: 3000, 0: 3000, 0], cmap = matplotlib.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize = [20, 20])\n",
    "axs.imshow(img_data.label[0: 3000, 0: 3000, 0], cmap = matplotlib.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(predictions), np.std(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_utils.image_IDs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions[:20,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_utils.test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(train_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(10): print sorted(train_utils.generate_train_ids(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 14, 10, 17]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_utils.test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 1, 2, 8, 24, 23, 18, 5, 6, 15, 0, 16, 20, 12, 11, 21, 9, 4, 7, 22, 3]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_utils.train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting class stats [========================] 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[19, 8, 15, 12, 16, 11, 18, 7]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_utils.generate_train_ids(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross entropy loss with no learning rate decay\n",
    "\n",
    "'log_dir/8-12_18-12_cross_entropy/ckpt/ckpt-11001'\n",
    "\n",
    "11: 1. flat\n",
    "10: 0.06 flat\n",
    "9: 0.1 flat\n",
    "8: 0.6, big chunk\n",
    "7: 0.95 flat\n",
    "6: 1.0 flat\n",
    "5: 0.1 flat\n",
    "4: ~1, flat\n",
    "3: ~0.95, flat\n",
    "2: 0.5 +- 0.5, pure strips!\n",
    "\n",
    "For lr of 0.1 and cross entropy loss balanced by the class weight, the training was never able to produce a working model. And the prediction is oscillating between 0.1 and 1\n",
    "\n",
    "I should try smaller lr of 0.001 and apply lr decay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross entropy loss with no learning rate decay\n",
    "\n",
    "'log_dir/8-13_5-21_cross_entropy/ckpt/ckpt-2001'\n",
    "start lr 0.001, this model again can never produce a stable working model. The mean prediction oscillates between 0.1 and 1. As the learning rate decays, the model converges to a model that tends to produce more true label prediction. ~50%. While the actual value is around 20%. This may be caused by the class balancing.\n",
    "\n",
    "In conclusion, cross entropy loss doesn't work! I need much larger mini batch to prevent performance oscillation.\n",
    "\n",
    "2: 0.97 flat\n",
    "3: 0.83 kinda flat\n",
    "4: 0.3 OK, a bit full\n",
    "5: 0.43, very full\n",
    "6: 0.14 very sparse\n",
    "7: 0.9 flat\n",
    "8: 0.8 kinda full\n",
    "9: 0.6 kinda full\n",
    "10: 0.5 kinda full\n",
    "11: 0.5 kinda full\n",
    "12: 0.5 kinda full\n",
    "13: 0.57 too full\n",
    "14: 0.55 too full"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
