{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import simplejson\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import threading\n",
    "import tensorflow.contrib.slim as slim\n",
    "from utils import data_utils, train_utils\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def argument_scope(H, phase):\n",
    "    '''\n",
    "    This returns the arg_scope for slim.arg_scope(), which defines the options for slim.functions\n",
    "    '''\n",
    "    padding = H['padding']\n",
    "    is_training = {'train': True, 'validate': False, 'test': False}[phase]\n",
    "    pool_kernel = [2, 2]\n",
    "    pool_stride = 2\n",
    "\n",
    "    \n",
    "    params = {\n",
    "        \"decay\": 0.997,\n",
    "        \"epsilon\": 0.001,\n",
    "    }\n",
    "\n",
    "    with slim.arg_scope([slim.conv2d], \n",
    "                        # slim.relu would raise an error here\n",
    "                        activation_fn=tf.nn.relu, \n",
    "                        padding=padding, \n",
    "                        normalizer_fn=slim.batch_norm, \n",
    "                        # normalizer_fn=None,\n",
    "                        weights_initializer=tf.contrib.layers.variance_scaling_initializer()):\n",
    "        with slim.arg_scope([slim.batch_norm, slim.dropout], is_training=is_training):\n",
    "            with slim.arg_scope([slim.max_pool2d], stride=pool_stride, kernel_size=pool_kernel):\n",
    "                with slim.arg_scope([slim.conv2d_transpose], \n",
    "                                    activation_fn=None, \n",
    "                                    normalizer_fn=None,\n",
    "                                    padding=padding, \n",
    "                                    weights_initializer=tf.contrib.layers.variance_scaling_initializer()) as sc:\n",
    "                    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_pred(x_in, H, phase):\n",
    "    '''\n",
    "    This function builds the prediction model\n",
    "    '''\n",
    "    num_class = H['num_class']\n",
    "    \n",
    "    conv_kernel_1 = [1, 1]\n",
    "    conv_kernel_3 = [3, 3]\n",
    "    pool_kernel = [2, 2]\n",
    "    pool_stride = 2\n",
    "\n",
    "    early_feature = {}\n",
    "    reuse = {'train': False, 'validate': True, 'test': False}[phase]\n",
    "    \n",
    "    with slim.arg_scope(argument_scope(H, phase)):\n",
    "        \n",
    "        scope_name = 'block_1'\n",
    "        x_input = x_in\n",
    "        num_outputs = 64\n",
    "        with tf.variable_scope(scope_name, reuse = reuse):\n",
    "            layer_1 = slim.conv2d(x_input, num_outputs, conv_kernel_3, scope='conv1')\n",
    "            layer_2 = slim.conv2d(layer_1, num_outputs, conv_kernel_3, scope='conv2')\n",
    "            early_feature[scope_name] = layer_2\n",
    "        \n",
    "        scope_name = 'block_2'\n",
    "        x_input = slim.max_pool2d(layer_2)\n",
    "        num_outputs = 128\n",
    "        with tf.variable_scope(scope_name, reuse = reuse):\n",
    "            layer_1 = slim.conv2d(x_input, num_outputs, conv_kernel_3, scope='conv1')\n",
    "            layer_2 = slim.conv2d(layer_1, num_outputs, conv_kernel_3, scope='conv2')\n",
    "            early_feature[scope_name] = layer_2\n",
    "\n",
    "        scope_name = 'block_3'\n",
    "        x_input = slim.max_pool2d(layer_2)\n",
    "        num_outputs = 256\n",
    "        with tf.variable_scope(scope_name, reuse = reuse):\n",
    "            layer_1 = slim.conv2d(x_input, num_outputs, conv_kernel_3, scope='conv1')\n",
    "            layer_2 = slim.conv2d(layer_1, num_outputs, conv_kernel_3, scope='conv2')\n",
    "            early_feature[scope_name] = layer_2\n",
    "            \n",
    "        scope_name = 'block_4'\n",
    "        x_input = slim.max_pool2d(layer_2)\n",
    "        num_outputs = 512\n",
    "        with tf.variable_scope(scope_name, reuse = reuse):\n",
    "            layer_1 = slim.conv2d(x_input, num_outputs, conv_kernel_3, scope='conv1')\n",
    "            layer_2 = slim.conv2d(layer_1, num_outputs, conv_kernel_3, scope='conv2')\n",
    "            early_feature[scope_name] = layer_2\n",
    "\n",
    "        scope_name = 'block_5'\n",
    "        x_input = slim.max_pool2d(layer_2)\n",
    "        num_outputs = 1024\n",
    "        with tf.variable_scope(scope_name, reuse = reuse):\n",
    "            layer_1 = slim.conv2d(x_input, num_outputs, conv_kernel_3, scope='conv1')\n",
    "            layer_2 = slim.conv2d(layer_1, num_outputs, conv_kernel_3, scope='conv2')\n",
    "            early_feature[scope_name] = layer_2\n",
    "            \n",
    "        scope_name = 'block_6'\n",
    "        num_outputs = 512\n",
    "        with tf.variable_scope(scope_name, reuse = reuse):\n",
    "            trans_layer = slim.conv2d_transpose(\n",
    "                layer_2, num_outputs, pool_kernel, pool_stride, scope='conv_trans')\n",
    "            x_input = tf.concat([early_feature['block_4'], trans_layer], axis=3)\n",
    "            layer_1 = slim.conv2d(x_input, num_outputs, conv_kernel_3, scope='conv1')\n",
    "            layer_2 = slim.conv2d(layer_1, num_outputs, conv_kernel_3, scope='conv2')\n",
    "            early_feature[scope_name] = layer_2\n",
    "            \n",
    "        scope_name = 'block_7'\n",
    "        num_outputs = 256\n",
    "        with tf.variable_scope(scope_name, reuse = reuse):\n",
    "            trans_layer = slim.conv2d_transpose(\n",
    "                layer_2, num_outputs, pool_kernel, pool_stride, scope='conv_trans')\n",
    "            x_input = tf.concat([early_feature['block_3'], trans_layer], axis=3)\n",
    "            layer_1 = slim.conv2d(x_input, num_outputs, conv_kernel_3, scope='conv1')\n",
    "            layer_2 = slim.conv2d(layer_1, num_outputs, conv_kernel_3, scope='conv2')\n",
    "            early_feature[scope_name] = layer_2\n",
    "            \n",
    "        scope_name = 'block_8'\n",
    "        num_outputs = 128\n",
    "        with tf.variable_scope(scope_name, reuse = reuse):\n",
    "            trans_layer = slim.conv2d_transpose(\n",
    "                layer_2, num_outputs, pool_kernel, pool_stride, scope='conv_trans')\n",
    "            x_input = tf.concat([early_feature['block_2'], trans_layer], axis=3)\n",
    "            layer_1 = slim.conv2d(x_input, num_outputs, conv_kernel_3, scope='conv1')\n",
    "            layer_2 = slim.conv2d(layer_1, num_outputs, conv_kernel_3, scope='conv2')\n",
    "            early_feature[scope_name] = layer_2\n",
    "        \n",
    "        scope_name = 'block_9'\n",
    "        num_outputs = 64\n",
    "        with tf.variable_scope(scope_name, reuse = reuse):\n",
    "            trans_layer = slim.conv2d_transpose(\n",
    "                layer_2, num_outputs, pool_kernel, pool_stride, scope='conv_trans')\n",
    "            x_input = tf.concat([early_feature['block_1'], trans_layer], axis=3)\n",
    "            layer_1 = slim.conv2d(x_input, num_outputs, conv_kernel_3, scope='conv1')\n",
    "            layer_2 = slim.conv2d(layer_1, num_outputs, conv_kernel_3, scope='conv2')\n",
    "            early_feature[scope_name] = layer_2\n",
    "        \n",
    "        scope_name = 'pred'\n",
    "        with tf.variable_scope(scope_name, reuse = reuse):\n",
    "            # layer_1 = slim.conv2d(layer_2, num_class, conv_kernel_1, scope='conv1', activation_fn=None, normalizer_fn=None)\n",
    "            layer_1 = slim.conv2d(layer_2, 1, conv_kernel_1, scope='conv1', activation_fn=None, normalizer_fn=None)\n",
    "\n",
    "            early_feature[scope_name] = layer_1\n",
    "            \n",
    "            # pred = tf.argmax(tf.nn.softmax(logits=layer_1), axis=3)\n",
    "            pred = tf.sigmoid(layer_1)\n",
    "                \n",
    "        return tf.squeeze(layer_1), tf.squeeze(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hypes = './hypes/hypes.json'\n",
    "with open(hypes, 'r') as f:\n",
    "    H = simplejson.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_in = tf.placeholder(dtype=tf.float32, shape=[1, 3200, 3200, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits, pred = build_pred(img_in, H, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 14, 10, 17]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_utils.test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_data = data_utils.ImageData(16)\n",
    "img_data.load_image()\n",
    "img_data.create_label()\n",
    "img_data.create_train_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from log_dir/8-13_20-0_combo-jaccard/ckpt/ckpt-10001\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, save_path='log_dir/8-13_20-0_combo-jaccard/ckpt/ckpt-10001')\n",
    "    predictions, log = sess.run([pred, logits], \n",
    "                                feed_dict = {img_in: np.reshape(img_data.train_feature[:3200, :3200, :], \n",
    "                                                                [1, 3200, 3200, 16])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3348, 3403, 16)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data.train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbc2905e2d0>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7gAAAG5CAYAAACk+pjXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQBUkuAAAAFRBggsAAEAV/n+gxamGr7l+HAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbc2906a1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize = [16, 8])\n",
    "axs[0].imshow((predictions > 0.5).astype(int)[0: 3000, 0: 3000], cmap = matplotlib.cm.gray)\n",
    "axs[1].imshow(img_data.label[0: 3000, 0: 3000, 0], cmap = matplotlib.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.038190085, 0.18303518)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predictions), np.std(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to experiment lr of 0.0001 w/o lr decay. In the previous setting the lr drops to 0.00013 at step 6000, and the NN seems to start to learn something at step 7000 and stablize at step 9000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beta1=0.8, beta2=0.99, lr = 0.001, loss = cross - log (jaccard), with lr decay. This is so far the best model.\n",
    "\n",
    "3: 0.46 big chunks\n",
    "4: 0.11 a lot missing parts\n",
    "5: 0.2 a lot of clusters\n",
    "6: 0.44 big chunks  lr = 0.00013\n",
    "7: 0.19 nice one\n",
    "8: 0.19 nice one\n",
    "9: 0.23 nice one\n",
    "10: 0.23 nice one   lr = 0.00003\n",
    "11: 0.23 nice one\n",
    "12: 0.24 nice one\n",
    "13: 0.23 nice one\n",
    "14: 0.24 nice one\n",
    "15: 0.22 nice one\n",
    "16: 0.23 nice one\n",
    "17: 0.23 nice one\n",
    "18: 0.23 nice one\n",
    "19: 0.23 nice one\n",
    "20: 0.23 nice one\n",
    "\n",
    "Another experiment was done with almost the same parameters but or of 0.01. The results oscillates. So This loss function also works, but lr of 0.001 is the best.\n",
    "\n",
    "'log_dir/8-13_17-48_combo-jaccard/ckpt/ckpt-7001'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'log_dir/8-12_14-32_combo-jaccard/ckpt/ckpt-16001'\n",
    "20: 0.072345264 very sparse\n",
    "19: 0.072345264 very sparse\n",
    "18: 0.02 super sparse\n",
    "17: 0.48 a bit full\n",
    "16: 0.1 too sparse\n",
    "15: 0.14 too sparse\n",
    "14: 0.36 OK kinda too full\n",
    "13: 0.2 better than 12\n",
    "12: 0.18 best, still some parts missing\n",
    "11: 0.03 flat\n",
    "10: 0.03 flat\n",
    "9: 0.97 flat\n",
    "8: 1.0 flat \n",
    "7: ~0.5 best\n",
    "6: ~1.0 flat\n",
    "5: ~0.98 flat\n",
    "4: 0.23 best OK rough image with strips\n",
    "3: 1.0 flat\n",
    "\n",
    "model 14 misclassifies road as buildings, model 13 doesn't\n",
    "model 13 can also make good predictions on images with no buildings (true labels). Model trained with images not including the no true label ones, would totally misclassfy these images\n",
    "\n",
    "The result is oscillating!!\n",
    "\n",
    "If the class is highly imblanced, you have to use really large batch size and large momentum, to make sure that the statistics of each effective (taking into account of the momentum) agrees with the statistics of whole training data set. Otherwise, the loss and accuracy will be oscillating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(log), np.std(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize = [16, 8])\n",
    "axs[0].imshow((predictions > 0.8).astype(int)[0: 3000, 0: 3000], cmap = matplotlib.cm.gray)\n",
    "axs[1].imshow(img_data.label[0: 3000, 0: 3000, 0], cmap = matplotlib.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize = [20, 20])\n",
    "axs.imshow(img_data.label[0: 3000, 0: 3000, 0], cmap = matplotlib.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(predictions), np.std(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_utils.image_IDs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions[:20,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_utils.test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(train_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(10): print sorted(train_utils.generate_train_ids(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_utils.test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_utils.train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_utils.generate_train_ids(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross entropy loss with no learning rate decay\n",
    "\n",
    "'log_dir/8-12_18-12_cross_entropy/ckpt/ckpt-11001'\n",
    "\n",
    "11: 1. flat\n",
    "10: 0.06 flat\n",
    "9: 0.1 flat\n",
    "8: 0.6, big chunk\n",
    "7: 0.95 flat\n",
    "6: 1.0 flat\n",
    "5: 0.1 flat\n",
    "4: ~1, flat\n",
    "3: ~0.95, flat\n",
    "2: 0.5 +- 0.5, pure strips!\n",
    "\n",
    "For lr of 0.1 and cross entropy loss balanced by the class weight, the training was never able to produce a working model. And the prediction is oscillating between 0.1 and 1\n",
    "\n",
    "I should try smaller lr of 0.001 and apply lr decay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross entropy loss with no learning rate decay\n",
    "\n",
    "'log_dir/8-13_5-21_cross_entropy/ckpt/ckpt-2001'\n",
    "start lr 0.001, this model again can never produce a stable working model. The mean prediction oscillates between 0.1 and 1. As the learning rate decays, the model converges to a model that tends to produce more true label prediction. ~50%. While the actual value is around 20%. This may be caused by the class balancing.\n",
    "\n",
    "In conclusion, cross entropy loss doesn't work! I need much larger mini batch to prevent performance oscillation.\n",
    "\n",
    "2: 0.97 flat\n",
    "3: 0.83 kinda flat\n",
    "4: 0.3 OK, a bit full\n",
    "5: 0.43, very full\n",
    "6: 0.14 very sparse\n",
    "7: 0.9 flat\n",
    "8: 0.8 kinda full\n",
    "9: 0.6 kinda full\n",
    "10: 0.5 kinda full\n",
    "11: 0.5 kinda full\n",
    "12: 0.5 kinda full\n",
    "13: 0.57 too full\n",
    "14: 0.55 too full"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
